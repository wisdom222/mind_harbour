import streamlit as st
import os
import json
import uuid
import re
from datetime import datetime
import asyncio

# --- Agno & Qdrant Imports ---
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.tools.tavily import TavilyTools 
from qdrant_client import QdrantClient, models

# ==========================================
# 0. å…¨å±€é…ç½® (è¯·åœ¨æ­¤å¤„å¡«å…¥ä½ çš„ Key)
# ==========================================
TAVILY_API_KEY = "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" 

# ==========================================
# 1. é¡µé¢åŸºç¡€é…ç½®ä¸ç–—æ„ˆç³» UI
# ==========================================
st.set_page_config(
    page_title="å¿ƒçµæ¸¯æ¹¾ | Mind Harbor",
    page_icon="ğŸŒ¿",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ³¨å…¥è‡ªå®šä¹‰ CSS
st.markdown("""
<style>
    .stApp { background-color: #F9F7F2; }
    .stChatMessage { background-color: transparent; border: none; padding: 15px 0; }
    div[data-testid="stChatMessage"] {
        padding: 1.2rem; border-radius: 18px; margin-bottom: 12px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.03);
        font-family: 'Helvetica Neue', sans-serif; line-height: 1.6;
    }
    div[data-testid="stChatMessage"][data-test-role="assistant"] {
        background-color: #FFFFFF; border-left: 4px solid #A3B18A; color: #4A4A4A;
    }
    div[data-testid="stChatMessage"][data-test-role="user"] {
        background-color: #DAD7CD; color: #3A3A3A; flex-direction: row-reverse; text-align: right;
    }
    h1 { color: #588157; font-weight: 300; text-align: center; margin-bottom: 30px; }
    section[data-testid="stSidebar"] { background-color: #F3F1EB; }
    .clinical-note {
        background-color: #EDF6F9; color: #457B9D; padding: 12px;
        border-radius: 8px; font-size: 0.85em; margin-top: 8px; border: 1px dashed #A8DADC;
    }
    .search-result {
        font-size: 0.8em; color: #666; border-left: 2px solid #E9C46A; padding-left: 10px; margin-bottom: 5px;
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. Vector DB é€»è¾‘ (æœ¬åœ°æ¨¡å¼)
# ==========================================
COLLECTION_NAME = "mind_harbor_memories"

def get_qdrant_client():
    return QdrantClient(path="./qdrant_local_storage")

def get_embedder():
    if not st.session_state.get('openai_api_key'):
        return None
    return OpenAIEmbedder(
        id="text-embedding-3-small",
        api_key=st.session_state['openai_api_key'],
        base_url=st.session_state.get('base_url', "https://api.zhizengzeng.com/v1")
    )

def ensure_collection_exists():
    client = get_qdrant_client()
    if not client: return
    if not client.collection_exists(COLLECTION_NAME):
        client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)
        )

def search_memory(username, query_text, limit=5):
    client = get_qdrant_client()
    embedder = get_embedder()
    if not client or not embedder: return "System: è®°å¿†æ¨¡å—æœªè¿æ¥(è¯·æ£€æŸ¥OpenAI Key)ã€‚"

    try:
        ensure_collection_exists()
        query_vector = embedder.get_embedding(query_text)
        search_result = client.search(
            collection_name=COLLECTION_NAME,
            query_vector=query_vector,
            query_filter=models.Filter(
                must=[models.FieldCondition(key="username", match=models.MatchValue(value=username))]
            ),
            limit=limit
        )
        if not search_result: return "æš‚æ— ç›¸å…³å†å²è®°å¿†ã€‚"
        return "\n".join([f"- [{hit.payload['timestamp']}] {hit.payload['text']}" for hit in search_result])
    except Exception as e:
        return f"è®°å¿†æ£€ç´¢å‡ºé”™: {e}"

def save_memory_fragment(username, memory_text):
    client = get_qdrant_client()
    embedder = get_embedder()
    if not client or not embedder: return False

    try:
        ensure_collection_exists()
        vector = embedder.get_embedding(memory_text)
        payload = {
            "username": username, "text": memory_text,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "type": "summary"
        }
        client.upsert(
            collection_name=COLLECTION_NAME,
            points=[models.PointStruct(id=str(uuid.uuid4()), vector=vector, payload=payload)]
        )
        return True
    except Exception as e:
        st.error(f"è®°å¿†ä¿å­˜å¤±è´¥: {e}")
        return False

# ==========================================
# 3. è¾…åŠ©å‡½æ•°ï¼šé²æ£’çš„ JSON è§£æ
# ==========================================
def robust_json_parse(text):
    """é˜²æ­¢ Agent è¾“å‡º Markdown æˆ–ä¸è§„èŒƒæ ¼å¼å¯¼è‡´å´©æºƒ"""
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass
    try:
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if match:
            return json.loads(match.group(0))
    except Exception:
        pass
    return {"insight": "æ•°æ®è§£ææš‚ä¸å¯ç”¨", "stress_score": 5, "distortion": "Unknown"}

# ==========================================
# 4. Session State åˆå§‹åŒ–
# ==========================================
DEFAULT_BASE_URL = "https://api.zhizengzeng.com/v1"

if 'messages' not in st.session_state: st.session_state['messages'] = []
if 'analysis_logs' not in st.session_state: st.session_state['analysis_logs'] = []
if 'emotion_scores' not in st.session_state: st.session_state['emotion_scores'] = [5]
if 'current_user' not in st.session_state: st.session_state['current_user'] = None
if 'temp_pill_input' not in st.session_state: st.session_state['temp_pill_input'] = None
if 'search_logs' not in st.session_state: st.session_state['search_logs'] = []
if 'dynamic_suggestions' not in st.session_state: 
    st.session_state['dynamic_suggestions'] = ["æœ€è¿‘æ„Ÿè§‰å¾ˆç´¯", "æˆ‘æƒ³èŠèŠäººé™…å…³ç³»", "æ€ä¹ˆç¼“è§£ç„¦è™‘ï¼Ÿ", "æˆ‘ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠ"]

if 'openai_api_key' not in st.session_state: st.session_state['openai_api_key'] = ''
if 'base_url' not in st.session_state: st.session_state['base_url'] = DEFAULT_BASE_URL

# ==========================================
# 5. ä¾§è¾¹æ 
# ==========================================
with st.sidebar:
    st.title("ğŸŒ¿ å’¨è¯¢å®¤æ¥å¾…å¤„")
    
    if not st.session_state['current_user']:
        st.info("è¯·ç™»å½•ä»¥è¯»å–æ‚¨çš„ä¸“å±æ¡£æ¡ˆ")
        username_input = st.text_input("è¯·è¾“å…¥æ‚¨çš„åå­—", placeholder="ä¾‹å¦‚: Ashley")
        if st.button("è¿›å…¥å’¨è¯¢å®¤"):
            if username_input:
                st.session_state['current_user'] = username_input
                welcome_text = f"ä½ å¥½ {username_input}ï¼Œæˆ‘æ˜¯ä½ çš„AIå¿ƒç†ä¼™ä¼´ã€‚è¿™é‡Œå¾ˆå®‰å…¨ï¼Œä½ å¯ä»¥ç•…æ‰€æ¬²è¨€ã€‚"
                st.session_state['messages'] = [{"role": "assistant", "content": welcome_text}]
                st.rerun()
    else:
        st.success(f"å½“å‰ç”¨æˆ·: **{st.session_state['current_user']}**")
        if st.button("ğŸšª é€€å‡º / åˆ‡æ¢è´¦å·"):
            st.session_state['current_user'] = None
            st.session_state['messages'] = []
            st.session_state['emotion_scores'] = [5]
            st.session_state['analysis_logs'] = []
            st.session_state['search_logs'] = []
            st.session_state['temp_pill_input'] = None
            st.session_state['dynamic_suggestions'] = ["æœ€è¿‘æ„Ÿè§‰å¾ˆç´¯", "æˆ‘æƒ³èŠèŠäººé™…å…³ç³»", "æ€ä¹ˆç¼“è§£ç„¦è™‘ï¼Ÿ"]
            st.rerun()
    
    st.divider()
    st.subheader("ğŸ“Š å¿ƒç†å‹åŠ›ç›‘æµ‹")
    if len(st.session_state['emotion_scores']) > 1:
        st.line_chart(st.session_state['emotion_scores'], height=150)
        curr = st.session_state['emotion_scores'][-1]
        prev = st.session_state['emotion_scores'][-2]
        st.metric("å½“å‰å‹åŠ›æŒ‡æ•° (0-10)", f"{curr}", f"{curr-prev}", delta_color="inverse")
    else:
        st.caption("æš‚æ— è¶³å¤Ÿæ•°æ®ï¼Œè¯·å¼€å§‹å¯¹è¯ã€‚")

    st.divider()
    with st.expander("âš™ï¸ ç³»ç»Ÿè®¾ç½®"):
        st.session_state['openai_api_key'] = st.text_input("OpenAI Key", type="password", value=st.session_state['openai_api_key'])
        st.session_state['base_url'] = st.text_input("Base URL", value=st.session_state['base_url'])
        
        st.info("ğŸ§  è®°å¿†åº“çŠ¶æ€: **æœ¬åœ°å†…ç½® (Local)**")
        st.info("ğŸ” æœç´¢æ’ä»¶: **Tavily (å·²å†…ç½®)**")
        
        if st.button("ğŸ§¹ æ¸…ç©ºå½“å‰å¯¹è¯"):
            if st.session_state['current_user']:
                st.session_state['messages'] = [{"role": "assistant", "content": "å¥½çš„ï¼Œæˆ‘ä»¬é‡æ–°å¼€å§‹ã€‚æ­¤åˆ»ä½ æ„Ÿè§‰å¦‚ä½•ï¼Ÿ"}]
                st.session_state['emotion_scores'] = [5]
                st.session_state['analysis_logs'] = []
                st.session_state['dynamic_suggestions'] = ["è¯´è¯´ä½ ç°åœ¨çš„æƒ³æ³•", "å¯ä»¥åšä¸ªæ·±å‘¼å¸", "æœ€è¿‘ç¡çœ æ€ä¹ˆæ ·ï¼Ÿ"]
                st.rerun()

if not st.session_state['openai_api_key']: st.warning("ğŸ”’ è¯·è¾“å…¥ OpenAI API Key"); st.stop()
if not st.session_state['current_user']: st.stop()

os.environ["OPENAI_API_KEY"] = st.session_state['openai_api_key']
os.environ["OPENAI_BASE_URL"] = st.session_state['base_url']

# ==========================================
# 6. Agent å®šä¹‰
# ==========================================
def get_model(model_id="gpt-4o"):
    return OpenAIChat(
        id=model_id,
        api_key=st.session_state['openai_api_key'],
        base_url=st.session_state['base_url']
    )

triage_agent = Agent(
    name="Guardian",
    model=get_model("gpt-4o-mini"),
    instructions=[
        "ä½ æ˜¯ä¸€ä¸ªå¿ƒç†å±æœºå¹²é¢„çš„å®‰å…¨å®ˆé—¨å‘˜ã€‚",
        "ä»»åŠ¡ï¼šåˆ†æç”¨æˆ·è¾“å…¥æ˜¯å¦åŒ…å«ï¼šè‡ªæ€æ„å¿µã€è‡ªæ®‹è®¡åˆ’ã€ä¸¥é‡æš´åŠ›å€¾å‘ã€‚",
        "è¾“å‡ºæ ¼å¼ï¼š'CRISIS_ALERT: <åŸå› >' æˆ– 'SAFE: <æƒ…ç»ªå…³é”®è¯>'ã€‚",
        "ä¸è¦è¾“å‡ºå…¶ä»–ä»»ä½•å†…å®¹ã€‚"
    ],
    markdown=False
)

analyst_agent = Agent(
    name="Logic",
    model=get_model("gpt-4o-mini"),
    instructions=[
        "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¸´åºŠå¿ƒç†åˆ†æå¸ˆã€‚",
        "ä»»åŠ¡ï¼šåˆ†æç”¨æˆ·è¾“å…¥å¹¶è¿”å›çº¯ JSON æ•°æ®ã€‚",
        "JSON å­—æ®µå¿…é¡»åŒ…å«ï¼š",
        "1. 'insight': ç®€çŸ­ä¸´åºŠè§‚å¯Ÿã€‚",
        "2. 'stress_score': 0-10 çš„æ•´æ•°ï¼ˆ10ä¸ºæœ€é«˜å‹åŠ›ï¼‰ã€‚",
        "3. 'distortion': è®¤çŸ¥æ‰­æ›²ç±»å‹ï¼ˆæ— åˆ™å¡«'None'ï¼‰ã€‚",
        "**é‡è¦**ï¼šä¸è¦ä½¿ç”¨ Markdown ä»£ç å—ï¼Œç›´æ¥è¿”å› JSON å­—ç¬¦ä¸²ã€‚",
        "Example: {\"insight\": \"ç”¨æˆ·æ„Ÿåˆ°ç„¦è™‘\", \"stress_score\": 7, \"distortion\": \"è¿‡åº¦æ¦‚æ‹¬\"}"
    ],
    markdown=False
)

router_agent = Agent(
    name="Router",
    model=get_model("gpt-4o-mini"),
    instructions=[
        "ä»»åŠ¡ï¼šåˆ¤æ–­ç”¨æˆ·æ„å›¾æ˜¯å¦éœ€è¦å¤–éƒ¨æœç´¢ã€‚",
        "å¦‚æœè¯¢é—®å…·ä½“è¯ç‰©ã€åœ°å€ã€ç§‘å­¦å®šä¹‰ã€ç»Ÿè®¡æ•°æ® -> è¾“å‡º 'SEARCH'ã€‚",
        "å¦‚æœæ˜¯æƒ…ç»ªå‘æ³„ã€å¯»æ±‚å®‰æ…°ã€é—²èŠ -> è¾“å‡º 'CHAT'ã€‚",
        "åªè¾“å‡ºä¸€ä¸ªå•è¯ã€‚"
    ],
    markdown=False
)

# [ä¿®æ”¹ç‚¹] ä½¿ç”¨å†…ç½®çš„ Tavily Key
navigator_tools = []
if TAVILY_API_KEY and "tvly-" in TAVILY_API_KEY:
    navigator_tools = [TavilyTools(api_key=TAVILY_API_KEY)]
else:
    # å¦‚æœæ²¡å¡« Keyï¼Œç»™ä¸€ä¸ªè­¦å‘Š (ä»…åœ¨æ§åˆ¶å°)
    print("Warning: TAVILY_API_KEY not set in code.")

navigator_agent = Agent(
    name="Navigator",
    model=get_model("gpt-4o-mini"),
    tools=navigator_tools,
    instructions=[
        "ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ã€‚ä½¿ç”¨ Tavily æœç´¢ç”¨æˆ·éœ€è¦çš„èµ„æºã€‚",
        "ç”¨ä¸­æ–‡ç®€æ´æ€»ç»“æœç´¢ç»“æœï¼Œä¼˜å…ˆæä¾›äº‹å®æ€§ä¿¡æ¯ã€‚"
    ],
    # show_tool_calls=False,
    markdown=True
)

therapist_agent = Agent(
    name="Therapist",
    model=get_model("gpt-4o"),
    instructions=[
        "ä½ ç°åœ¨æ˜¯â€˜å¿ƒçµæ¸¯æ¹¾â€™çš„ä¸“ä¸šå¿ƒç†å’¨è¯¢å¸ˆâ€˜å°å®‰â€™ã€‚",
        "é£æ ¼ï¼šäººæœ¬ä¸»ä¹‰ã€æ¸©æš–æ”¯æŒã€åŒç†å¿ƒã€‚",
        "å¦‚æœæä¾›äº†[RESOURCE SEARCH RESULTS]ï¼Œè‡ªç„¶åœ°èå…¥å¯¹è¯ã€‚",
        "å‚è€ƒ[RELEVANT MEMORIES]è®©å¯¹è¯æœ‰è¿ç»­æ€§ã€‚",
        "ç”¨ä¸­æ–‡å›ç­”ã€‚"
    ],
    markdown=True
)

archivist_agent = Agent(
    name="Archivist",
    model=get_model("gpt-4o-mini"),
    instructions=[
        "ä»»åŠ¡ï¼šå°†å¯¹è¯æ€»ç»“ä¸ºç®€æ´çš„é•¿æœŸè®°å¿†ç‰‡æ®µã€‚",
        "è¾“å‡ºçº¯æ–‡æœ¬æ‘˜è¦ã€‚"
    ],
    markdown=True
)

suggester_agent = Agent(
    name="Suggester",
    model=get_model("gpt-4o-mini"),
    instructions=[
        "ä»»åŠ¡ï¼šæ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆ 3 ä¸ªç®€çŸ­çš„ç”¨æˆ·åç»­å›å¤å»ºè®®ã€‚",
        "æ ¼å¼ï¼šç”¨è‹±æ–‡é€—å·åˆ†éš”çš„çº¯æ–‡æœ¬ã€‚ä¾‹å¦‚ï¼š'æˆ‘æƒ³å¤šèŠèŠ, å¥½çš„è°¢è°¢, è¿˜æœ‰åˆ«çš„æ–¹æ³•å—'ã€‚"
    ],
    markdown=False
)

# ==========================================
# 7. å¯¹è¯æµç¼–æ’ (ä¿®å¤ Error é€»è¾‘)
# ==========================================
async def run_parallel_analysis(user_input):
    task_triage = asyncio.to_thread(triage_agent.run, f"ç”¨æˆ·è¾“å…¥: {user_input}")
    task_analyst = asyncio.to_thread(analyst_agent.run, f"ç”¨æˆ·è¾“å…¥: {user_input}")
    task_router = asyncio.to_thread(router_agent.run, f"ç”¨æˆ·è¾“å…¥: {user_input}")
    
    return await asyncio.gather(task_triage, task_analyst, task_router)

def process_conversation_turn(user_input):
    # A. Memory Retrieval
    with st.spinner("ğŸ§  æ­£åœ¨å›æº¯è®°å¿†..."):
        relevant_memories = search_memory(st.session_state['current_user'], user_input)
    
    short_term_history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state['messages'][-10:]])
    
    with st.status("ğŸƒ æ­£åœ¨ç”¨å¿ƒå€¾å¬...", expanded=False) as status:
        
        # B. Parallel Analysis
        status.write("âš¡ æ­£åœ¨æ„ŸçŸ¥æƒ…ç»ªä¸æ„å›¾...")
        try:
            triage_resp, analyst_resp, router_resp = asyncio.run(run_parallel_analysis(user_input))
        except Exception as e:
            return f"ç³»ç»Ÿåˆ†ææ¨¡å—å‡ºé”™: {str(e)}"

        # 1. Check Safety
        if "CRISIS_ALERT" in triage_resp.content:
            status.update(label="âš ï¸ å®‰å…¨æ‹¦æˆª", state="error")
            return f"ğŸš¨ **ç´§æ€¥å®‰å…¨æç¤º**\n\næ£€æµ‹åˆ°æ½œåœ¨é«˜é£é™©ã€‚è¯·ç«‹å³å¯»æ±‚ä¸“ä¸šå¸®åŠ©ã€‚\nReason: {triage_resp.content}"
        
        current_emotion = triage_resp.content.replace("SAFE:", "").strip()

        # 2. Parse Analyst Data (ä½¿ç”¨ Robust JSON Parse)
        data = robust_json_parse(analyst_resp.content)
        score = int(data.get("stress_score", 5))
        insight = data.get("insight", "")
        distortion = data.get("distortion", "None")
        
        st.session_state['emotion_scores'].append(score)
        st.session_state['analysis_logs'].append(f"å‹åŠ›: {score} | æ‰­æ›²: {distortion} | {insight}")

        # 3. Handle Search Intent (Tavily Search)
        search_results = "æœ¬æ¬¡æ— éœ€å¤–éƒ¨æœç´¢ã€‚"
        intent = router_resp.content.strip()
        
        if "SEARCH" in intent:
            status.write("ğŸŒ æ­£åœ¨å°è¯•è¿æ¥å¤–éƒ¨ç½‘ç»œ...")
            if not navigator_tools:
                 search_results = "ã€ç³»ç»Ÿæç¤ºã€‘ä»£ç ä¸­æœªæ­£ç¡®é…ç½® Tavily Keyï¼Œæ— æ³•æœç´¢ã€‚"
                 st.session_state['search_logs'].append(f"âš ï¸ æœç´¢å¤±è´¥: Keyæœªé…ç½®")
            else:
                try:
                    nav_response = navigator_agent.run(f"è¯·æœç´¢: {user_input}")
                    if nav_response and nav_response.content:
                        search_results = nav_response.content
                        st.session_state['search_logs'].append(f"ğŸ” Tavilyæœç´¢æˆåŠŸ: {user_input[:10]}...")
                    else:
                        search_results = "æœç´¢æœªè¿”å›ç»“æœã€‚"
                        st.session_state['search_logs'].append(f"ğŸ” æœç´¢æ— ç»“æœ")
                except Exception as e:
                    search_results = f"ã€ç³»ç»Ÿæç¤ºã€‘æœç´¢æœåŠ¡è¿æ¥å¤±è´¥: {str(e)}"
                    st.session_state['search_logs'].append(f"âš ï¸ æœç´¢å¤±è´¥: {str(e)}")
        else:
            st.session_state['search_logs'].append("ğŸ’­ çº¯å¯¹è¯æ¨¡å¼")

        # C. Generate Response
        status.write("ğŸŒ¿ æ­£åœ¨ç”Ÿæˆæ¸©æš–å›å¤...")
        
        full_prompt = f"""
        [RELEVANT MEMORIES]
        {relevant_memories}
        
        [RESOURCE SEARCH RESULTS]
        {search_results}
        
        [SHORT-TERM HISTORY]
        {short_term_history}
        
        [CURRENT SITUATION]
        ç”¨æˆ·è¾“å…¥: {user_input}
        å½“å‰æƒ…ç»ª: {current_emotion}
        åˆ†æå¸ˆè§‚å¯Ÿ: {insight}
        
        [INSTRUCTION]
        è¯·è‡ªç„¶åœ°å›åº”ç”¨æˆ·ã€‚å¦‚æœ[RESOURCE SEARCH RESULTS]æç¤ºç¼ºå°‘ Key æˆ–æœç´¢å¤±è´¥ï¼Œè¯·æ ¹æ®é€šç”¨å¿ƒç†å­¦çŸ¥è¯†è¿›è¡Œå®‰æŠšï¼Œä¸è¦ç›´æ¥æš´éœ²æŠ€æœ¯é”™è¯¯ä¿¡æ¯ã€‚
        """
        
        therapist_resp = therapist_agent.run(full_prompt)
        response_content = therapist_resp.content

        # D. Generate Dynamic Suggestions
        try:
            sugg_resp = suggester_agent.run(f"ç”¨æˆ·: {user_input}\nAI: {response_content}\nç”Ÿæˆ3ä¸ªç®€çŸ­å›å¤å»ºè®®ï¼Œé€—å·åˆ†éš”ã€‚")
            raw_suggs = sugg_resp.content.replace("ï¼Œ", ",").split(",")
            clean_suggs = [s.strip() for s in raw_suggs if s.strip()][:3]
            if clean_suggs:
                st.session_state['dynamic_suggestions'] = clean_suggs
        except:
            pass

        status.update(label="å›å¤å®Œæˆ", state="complete")
        return response_content

# ==========================================
# 8. UI ä¸»æ¸²æŸ“åŒº
# ==========================================
st.title("ğŸŒ¿ å¿ƒçµæ¸¯æ¹¾")
st.caption(f"Mind Harbor | å½“å‰æ¥è®¿è€…: {st.session_state['current_user']}")

chat_container = st.container()
with chat_container:
    for msg in st.session_state['messages']:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

def pill_callback():
    if st.session_state.pill_selection:
        st.session_state['temp_pill_input'] = st.session_state.pill_selection
        st.session_state.pill_selection = None

suggestions = st.session_state.get('dynamic_suggestions', ["æœ€è¿‘å‹åŠ›æœ‰ç‚¹å¤§", "å³ä½¿ç¡ç€äº†ä¹Ÿå¾ˆç´¯", "æ€ä¹ˆæ‰èƒ½æ§åˆ¶æƒ…ç»ªï¼Ÿ"])
st.pills("ğŸ’¬ è¯•è¯•è¯´ï¼ˆç‚¹å‡»å‘é€ï¼‰ï¼š", suggestions, selection_mode="single", key="pill_selection", on_change=pill_callback)

user_final_input = None
if st.session_state['temp_pill_input']:
    user_final_input = st.session_state['temp_pill_input']
    st.session_state['temp_pill_input'] = None
chat_input_val = st.chat_input("åœ¨æ­¤è¾“å…¥æ‚¨çš„æ„Ÿå—...")
if chat_input_val: user_final_input = chat_input_val

if user_final_input:
    with st.chat_message("user"): st.markdown(user_final_input)
    st.session_state['messages'].append({"role": "user", "content": user_final_input})
    
    try:
        response_text = process_conversation_turn(user_final_input)
        with st.chat_message("assistant"): st.markdown(response_text)
        st.session_state['messages'].append({"role": "assistant", "content": response_text})
        st.rerun()
    except Exception as e:
        st.error(f"è¿æ¥ä¸­æ–­æˆ–å‡ºé”™: {e}")

# ==========================================
# 9. åº•éƒ¨åŠŸèƒ½åŒº
# ==========================================
st.markdown("---")
col1, col2 = st.columns([3, 1])

with col1:
    if st.session_state['analysis_logs']:
        st.markdown("**ğŸ‘©â€âš•ï¸ å’¨è¯¢æ‰‹è®°:**")
        st.markdown(f"<div class='clinical-note'>{st.session_state['analysis_logs'][-1]}</div>", unsafe_allow_html=True)
    if st.session_state['search_logs']:
        st.caption(f"ç³»ç»ŸçŠ¶æ€: {st.session_state['search_logs'][-1]}")

with col2:
    if st.button("ğŸ’¾ ç»“æŸå¹¶ä¿å­˜è®°å¿†"):
        if len(st.session_state['messages']) < 2:
            st.warning("å¯¹è¯å¤ªçŸ­ï¼Œæš‚æ— å†…å®¹ã€‚")
        else:
            with st.spinner("æ­£åœ¨ä¿å­˜è‡³æœ¬åœ°..."):
                full_text = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state['messages']])
                summary_resp = archivist_agent.run(f"ä¼šè¯è®°å½•:\n{full_text}\n\nä»»åŠ¡: ç”Ÿæˆä¸­æ–‡æ‘˜è¦ã€‚")
                success = save_memory_fragment(st.session_state['current_user'], summary_resp.content)
                if success:
                    st.success("âœ… ä¿å­˜æˆåŠŸï¼")
                    with st.expander("æ‘˜è¦"): st.markdown(summary_resp.content)
                else:

                    st.error("ä¿å­˜å¤±è´¥ã€‚")
